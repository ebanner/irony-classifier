{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = '/u/ebanner/Classes/nlp/Project/irony-classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = '/u/npockrus/NLP/finalProject/venv/src/irony-classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/v/filer4b/v20q001/ebanner/Classes/nlp/Project/irony-classifier/data/progressive/features\n"
     ]
    }
   ],
   "source": [
    "cd /{base}/data/progressive/features/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Progressive Comments, Sentiment, and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "with open('text-sentiment-label.p', 'r') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Load comments, labels, and bow vectors\n",
    "progressive_sentences = np.array([ comment for comment in data ])\n",
    "progressive_sentiments = np.array([ data[comment]['sentiment'] for comment in data ])\n",
    "progressive_labels = np.array([ data[comment]['label'] for comment in data ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Down to Just Genuine Comments and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Filter down to just genuine comments and tokenize them\n",
    "genuine_sentences = [ x for x, y in zip(progressive_sentences, progressive_labels) if y == -1 ]\n",
    "genuine_sentences = [ ' '.join(word_tokenize(genuine_sentence)) for genuine_sentence in genuine_sentences ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Genuine Tokenized Comments to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('genuine-progressive.txt', 'w') as f:\n",
    "    for genuine_sentence in genuine_sentences:\n",
    "        f.write(genuine_sentence.encode('utf-8') + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an Arpa Straight From Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/v/filer4b/v20q001/ebanner/Classes/nlp/Project/irony-classifier/lib/berkeleylm-1.1.5/examples\n"
     ]
    }
   ],
   "source": [
    "cd /{base}/lib/berkeleylm-1.1.5/examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading text files [genuine-progressive.txt] and writing to file genuine-progressive.arpa {\n",
      "\tReading in ngrams from raw text {\n",
      "\t\tOn line 0\n",
      "\t} [0s]\n",
      "\tWriting Kneser-Ney probabilities {\n",
      "\t\tCounting counts for order 0 {\n",
      "\t\t} [0s]\n",
      "\t\tCounting counts for order 1 {\n",
      "\t\t} [0s]\n",
      "\t\tCounting counts for order 2 {\n",
      "\t\t} [0s]\n",
      "\t\tCounting counts for order 3 {\n",
      "\t\t} [0s]\n",
      "\t\tCounting counts for order 4 {\n",
      "\t\t} [0s]\n",
      "\t\tWriting ARPA {\n",
      "\t\t\tOn order 1\n",
      "\t\t\tWriting line 1\n",
      "\t\t\tOn order 2\n",
      "\t\t\tWriting line 1\n",
      "\t\t\tWriting line 10001\n",
      "\t\t\tWriting line 20001\n",
      "\t\t\tOn order 3\n",
      "\t\t\tWriting line 1\n",
      "\t\t\tWriting line 10001\n",
      "\t\t\tWriting line 20001\n",
      "\t\t\tWriting line 30001\n",
      "\t\t\tOn order 4\n",
      "\t\t\tWriting line 1\n",
      "\t\t\tWriting line 10001\n",
      "\t\t\tWriting line 20001\n",
      "\t\t\tWriting line 30001\n",
      "\t\t\tOn order 5\n",
      "\t\t\tWriting line 1\n",
      "\t\t\tWriting line 10001\n",
      "\t\t\tWriting line 20001\n",
      "\t\t\tWriting line 30001\n",
      "\t\t} [1s]\n",
      "\t} [1s]\n"
     ]
    }
   ],
   "source": [
    "!java -ea -mx1000m -server -cp ../src edu.berkeley.nlp.lm.io.MakeKneserNeyArpaFromText 5 genuine-progressive.arpa genuine-progressive.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Binary Trom the Arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Lm File genuine-progressive.arpa . . .  {\n",
      "\tCounting values {\n",
      "\t\tParsing ARPA language model file {\n",
      "\t\t\tReading 1-grams {\n",
      "\t\t\t\tRead 0 lines\n",
      "\t\t\t\t6667 1-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 2-grams {\n",
      "\t\t\t\t26839 2-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 3-grams {\n",
      "\t\t\t\t37469 3-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 4-grams {\n",
      "\t\t\t\t559 4-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 5-grams {\n",
      "\t\t\t} [0s]\n",
      "\t\t} [0s]\n",
      "\t\tCleaning up values {\n",
      "\t\t\tFound 29268 unique counts\n",
      "\t\t} [0s]\n",
      "\t} [0s]\n",
      "\tStoring values {\n",
      "\t\tStoring count indices using 15 bits.\n",
      "\t} [0s]\n",
      "\tAdding n-grams {\n",
      "\t\tParsing ARPA language model file {\n",
      "\t\t\tReading 1-grams {\n",
      "\t\t\t\tRead 0 lines\n",
      "\t\t\t\t6667 1-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 2-grams {\n",
      "\t\t\t\t26839 2-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 3-grams {\n",
      "\t\t\t\t37469 3-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 4-grams {\n",
      "\t\t\t\t559 4-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 5-grams {\n",
      "\t\t\t} [0s]\n",
      "\t\t} [0s]\n",
      "\t} [0s]\n",
      "\t37 missing suffixes or prefixes were found, doing another pass to add n-grams {\n",
      "\t\tParsing ARPA language model file {\n",
      "\t\t\tReading 1-grams {\n",
      "\t\t\t\tRead 0 lines\n",
      "\t\t\t\t6667 1-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 2-grams {\n",
      "\t\t\t\t26839 2-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 3-grams {\n",
      "\t\t\t\t37469 3-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 4-grams {\n",
      "\t\t\t\t559 4-gram read.\n",
      "\t\t\t} [0s]\n",
      "\t\t\tReading 5-grams {\n",
      "\t\t\t} [0s]\n",
      "\t\t} [0s]\n",
      "\t\tLoad factor for 1: 1.0\n",
      "\t\tLoad factor for 2: 0.7291225210540614\n",
      "\t\tLoad factor for 3: 0.7087944308873881\n",
      "\t\tLoad factor for 4: 0.7509481668773704\n",
      "\t\tLoad factor for 5: 0.7961165048543689\n",
      "\t} [0s]\n",
      "} [0s]\n",
      "Writing to file genuine-progressive.binary . . .  {\n",
      "} [0s]\n"
     ]
    }
   ],
   "source": [
    "!java -ea -mx1000m -server -cp ../src edu.berkeley.nlp.lm.io.MakeLmBinaryFromArpa genuine-progressive.arpa genuine-progressive.binary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
